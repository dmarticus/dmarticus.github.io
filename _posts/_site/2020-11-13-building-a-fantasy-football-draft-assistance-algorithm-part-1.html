<h3 id="part-one--choosing-the-model-dealing-with-the-data-and-generating-the-model">Part One – choosing the model, dealing with the data, and generating the model</h3>

<h2 id="context">Context</h2>

<p>I’m in a competitive fantasy football league with some friends, with a lot of pride (and a non-insignificant amount of money) on the line.  So, when we started the season, I wanted to find any edge I could to help me draft against them (if you’re not familiar with fantasy football, <a href="https://www.vox.com/2014/8/15/6003131/fantasy-football-how-to-play-draft-rankings">read this first</a>).</p>

<p>Drafting is a core part of fantasy football, and most fantasy football platforms have a recommendation system to assist with drafting players, but I wanted to make my own – as a learning exercise for myself, but mostly as a way to try and beat the recommendations provided by our platform (ESPN).  ESPN’s recommendations only use one dataset (their own) for projecting pre-season player <a href="https://stmorse.github.io/journal/espn-fantasy-projections.html">projections</a>, and I wanted to see that if I combined several different fantasy fantasy football projection datasets, I could come up with more accurate model for the probability distribution that generates the projected point totals for each player.  Hopefully, that model would give me that edge I was looking for.  Ultimately, my goal was to make some sort of app that I could run while I was drafting and into which I could feed (1) the player picked and (2) the position in the draft in which that player was picked, and it would return the best possible candidate for every position when it was my turn to pick.  I decided to call this app “DAsHA”, which stands for “Draft Assistance Heuristic Algorithm”.</p>

<p>This post is Part One of how I built DAsHA – here, I’ll cover the model that I used to project player performance (and the reason I chose it), how I collected and prepared the various datasets that I needed, and how I generated the model to power the algorithm.</p>

<h2 id="choosing-the-model">Choosing the Model</h2>

<p>Fantasy football point projections are powered by probability distributions – each player has a given probability of scoring your team a given number of points based on the player’s skill, their position, and their week-over-week matchup.  Therefore, the model I needed to use had to be one that could estimate a probability density function.  One of the classic tools for this type of estimation is a <a href="https://en.wikipedia.org/wiki/Histogram">histogram</a>, which works by plotting a curve over a series of buckets that represent different subsets of the range of values in the dataset, and then the data are sorted into the buckets to represent frequency (with the higher buckets representing values that occur more frequently in the dataset).  You can fit a Gaussian curve to a histogram to normalize the data, and this gives you a relatively accurate estimation for assessing the probability distribution of a given variable (in our case, fantasy points).</p>

<p>However, one of the drawbacks of a histogram is in its simplicity – since a histogram only uses buckets to represent the data distribution means, the curve that can be fit to a histogram doesn’t actually use all of the sample points: it just uses the buckets.  So while modeling my data with a Gaussian histogram seemed like a promising start, I was worried that the curve generated from my histogram wouldn’t be accurate enough to outperform the ESPN projections.</p>

<p>This is where kernel density estimation comes into play.  Kernel density estimation is a technique for estimating a probability density function (PDF) that can often outperform histograms, depending on what you want to do. Unlike the histogram, the kernel technique produces smooth estimate of the PDF, uses all sample points’ locations, and more convincingly suggests multimodality.  In my case, since I planned on using multiple different buckets of potential scoring projections, I wanted to take advantage of this multimodality, and leverage any potential insights buried therein.</p>

<p>Fortunately, Python has some excellent libraries for implementing Gaussian (Normalized) Kernel Density Estimations (KDEs), and it’s generally a great language for quickly prototyping any sort of data science problem.  But before I could do the science, I needed some actual data.</p>

<h2 id="dealing-with-the-data">Dealing with the Data</h2>

<h3 id="step-1---collecting-the-data">Step 1 - Collecting the data</h3>

<p>I wanted a diverse set of projections to improve the accuracy of my KDE, so I collected the projected player performance data from five fantasy football data sources: <a href="https://fantasy.espn.com/football/players/projections?leagueFormatId=1">ESPN</a>, <a href="https://www.fantasysharks.com/apps/Projections/SeasonProjections.php?pos=ALL">Fantasy Sharks</a>, <a href="https://www.fantasypros.com/nfl/rankings/consensus-cheatsheets.php?loggedin=&amp;my-experts=ALL">Fantasy Pros</a>, <a href="https://fftoolbox.fulltimefantasy.com/football/rankings/index.php?noppr=true">Fantasy Football Toolbox</a>, and <a href="https://fantasy.nfl.com/research/projections?position=O&amp;sort=projectedPts&amp;statCategory=projectedStats&amp;statSeason=2020&amp;statType=seasonProjectedStats#researchProjections=researchProjections%2C%2Fresearch%2Fprojections%253Fposition%253DO%2526statCategory%253DprojectedStats%2526statSeason%253D2020%2526statType%253DseasonProjectedStats%2526statWeek%253D1%2Creplace">NFL.com</a>.  I also used <a href="https://football.fantasysports.yahoo.com/f1/826195/1/editprerank">Yahoo!</a>, but their projections, rather than fantasy points, were the the projected fantasy draft positions (this would become important later).</p>

<p>Collecting this data posed a challenge initially, since none of these sources had public APIs (not surprising, but still sad) that I could figure out how to work with, and I didn’t want to write some sort of HTML scraper to import the data into a CSV (nor did I want to reverse-engineer the APIs that they were using to generate the data). Fortunately, though, after a little research (turns out there are a LOT of sports bloggers out there who do stuff like this), I found out that Excel has a native method to <a href="https://www.spreadsheetsports.com/free-tools/how-to-download-sport-data-into-a-spreadsheet/">import data from the web</a> that just worked out of the box for the above links.  Using this speedy approach, I made an Excel spreadsheet for each data source and put them all into the <code class="language-plaintext highlighter-rouge">/raw_data</code> directory at the root of my project, like so.</p>

<div class="language-text highlighter-rouge"><div class="highlight"><pre class="highlight"><code>raw_data/
    |-- Yahoo_2020_Draft_Positions.xlsx
    |-- Fantasy_Pros_2020_proj.xlsx
    |-- NFL_2020_proj.xlsx'
    |-- Fantasy_Shark_2020_proj.xlsx
    |-- Sports_Illustrated_2020_proj.xls
    |-- ESPN_2020_proj.xlsx
</code></pre></div></div>

<h3 id="step-2---preparing-the-data">Step 2 - Preparing the data</h3>

<p>Now that I had the data, I could start working on generating the Gaussian KDE.  First, I needed to import all the necessary data science libraries that provide user-friendly APIs to help me with that math that I’d need to generate the model.  For this project, I used <a href="https://numpy.org/">NumPy</a>, <a href="https://pandas.pydata.org/">pandas</a>, <a href="https://matplotlib.org/">matplotlib</a>, <a href="https://www.scipy.org/">SciPy</a>, and <a href="https://www.statsmodels.org/stable/index.html">statsmodels</a>.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="n">np</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="n">pd</span>
<span class="o">%</span><span class="n">matplotlib</span> <span class="n">inline</span>
<span class="kn">from</span> <span class="nn">scipy</span> <span class="kn">import</span> <span class="n">stats</span>
<span class="kn">import</span> <span class="nn">statsmodels.api</span> <span class="k">as</span> <span class="n">sm</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="n">plt</span>
<span class="kn">from</span> <span class="nn">statsmodels.distributions.mixture_rvs</span> <span class="kn">import</span> <span class="n">mixture_rvs</span>
</code></pre></div></div>

<p>Next, I had to combine everything together into one dataframe.  I decided to combine everything together and use the player names from the Yahoo! draft list as the primary index, since my goal for DAsHA is to look up information based on the player nam.  What this meant was that my dataframe looked like a 2-dimensional matrix where every player had a list of projected points that corresponded to the various projections that I’d collected.  I implemented it like this:</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># load Yahoo! draft positions
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">'./raw_data/Yahoo_2020_Draft_Positions.xlsx'</span><span class="p">)</span>
<span class="c1"># strip the names so they can be directly compared to other lists
</span><span class="n">df</span><span class="p">[</span><span class="s">'Name'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s">'Name'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span> 

<span class="c1"># load Fantasy Pros Projections
</span><span class="n">df_fantasy_pros</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">'./raw_data/Fantasy_Pros_2020_proj.xlsx'</span><span class="p">)</span>

<span class="c1"># construct temporary data frame to merge relevant info
</span><span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">df_temp</span><span class="p">[</span><span class="s">'Name'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_fantasy_pros</span><span class="p">[</span><span class="s">'PLAYER'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span>
<span class="n">df_temp</span><span class="p">[</span><span class="s">'fp_pts'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_fantasy_pros</span><span class="p">[</span><span class="s">'FAN PTS'</span><span class="p">]</span>

<span class="c1"># merge df with temporary df
</span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">df_temp</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'Name'</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span><span class="s">'outer'</span><span class="p">)</span>

<span class="c1"># import NFL projections
</span><span class="n">df_nfl</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">'./raw_data/NFL_2020_proj.xlsx'</span><span class="p">)</span>
<span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">df_temp</span><span class="p">[</span><span class="s">'Name'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_nfl</span><span class="p">[</span><span class="s">'PLAYER'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span>
<span class="n">df_temp</span><span class="p">[</span><span class="s">'nfl_pts'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_nfl</span><span class="p">[</span><span class="s">'POINTS'</span><span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">df_temp</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'Name'</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span><span class="s">'outer'</span><span class="p">)</span>

<span class="c1"># import ESPN projections
</span><span class="n">df_espn</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">'./raw_data/ESPN_2020_proj.xlsx'</span><span class="p">)</span>
<span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">df_temp</span><span class="p">[</span><span class="s">'Name'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_espn</span><span class="p">[</span><span class="s">'PLAYER'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span>
<span class="n">df_temp</span><span class="p">[</span><span class="s">'espn_pts'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_espn</span><span class="p">[</span><span class="s">'TOT'</span><span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">df_temp</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'Name'</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span><span class="s">'outer'</span><span class="p">)</span>

<span class="c1"># import Fantasy Shark projections
</span><span class="n">df_fantasy_shark</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">'./raw_data/Fantasy_Shark_2020_proj.xlsx'</span><span class="p">)</span>
<span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">df_temp</span><span class="p">[</span><span class="s">'Name'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_fantasy_shark</span><span class="p">[</span><span class="s">'Name'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span>
<span class="n">df_temp</span><span class="p">[</span><span class="s">'fs_pts'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_fantasy_shark</span><span class="p">[</span><span class="s">'Fantasy Points'</span><span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">df_temp</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'Name'</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span><span class="s">'outer'</span><span class="p">)</span>

<span class="c1"># import Sports Illustrated projections
</span><span class="n">df_si</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">read_excel</span><span class="p">(</span><span class="s">'./raw_data/Sports_Illustrated_2020_proj.xlsx'</span><span class="p">)</span>
<span class="n">df_temp</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">DataFrame</span><span class="p">()</span>
<span class="n">df_temp</span><span class="p">[</span><span class="s">'Name'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_si</span><span class="p">[</span><span class="s">'PLAYER'</span><span class="p">].</span><span class="nb">str</span><span class="p">.</span><span class="n">strip</span><span class="p">()</span>
<span class="n">df_temp</span><span class="p">[</span><span class="s">'si_pts'</span><span class="p">]</span> <span class="o">=</span> <span class="n">df_si</span><span class="p">[</span><span class="s">'POINTS'</span><span class="p">]</span>

<span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="p">.</span><span class="n">merge</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">df_temp</span><span class="p">,</span> <span class="n">on</span><span class="o">=</span><span class="s">'Name'</span><span class="p">,</span> <span class="n">how</span> <span class="o">=</span><span class="s">'outer'</span><span class="p">)</span>

<span class="c1"># Finally, drop the players not available in Yahoo!
</span><span class="n">df</span> <span class="o">=</span> <span class="n">df</span><span class="p">.</span><span class="n">dropna</span><span class="p">(</span><span class="n">subset</span><span class="o">=</span><span class="p">[</span><span class="s">'Draft Position'</span><span class="p">])</span>
</code></pre></div></div>

<p>Running that code gave me the 2-D matrix I needed.  Now for the non-parametric fun!</p>

<h2 id="generating-the-gaussian-kernel-density-estimation">Generating the Gaussian Kernel Density Estimation</h2>

<p>Dataframe in hand, I then created a Gaussian KDE for each player using the projected points from each source as the kernels.  Each player had 5 sources, so I’d have 5 different kernels per player.</p>

<p>The following code snippet implements the non-parametric estimations for each player.  It calculates (1) the median value from the KDE as projected points and (2) the inverse Cumulative Distribution Function (CDF) as an array in <code class="language-plaintext highlighter-rouge">kde_icdf</code> so we can generate the non-parametric confidence intervals for DAsHA.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="c1"># create an empty column to store point projections for each player
</span><span class="n">df</span><span class="p">[</span><span class="s">'pts'</span><span class="p">]</span> <span class="o">=</span> <span class="n">np</span><span class="p">.</span><span class="n">nan</span>

<span class="c1"># create an empty column to store the inverse cumulative 
# density function (icdf) data for each player's kde estimation
</span><span class="n">df</span><span class="p">[</span><span class="s">'kde_icdf'</span><span class="p">]</span> <span class="o">=</span> <span class="p">[[]</span> <span class="k">for</span> <span class="n">_</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">))]</span>

<span class="c1"># start from index 67 because the first 66 entries in my df
# are contextual cruft and not training data
</span><span class="k">for</span> <span class="n">j</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">66</span><span class="p">,</span><span class="nb">len</span><span class="p">(</span><span class="n">df</span><span class="p">)):</span>
    <span class="c1"># this block constructs an array of training 
</span>    <span class="c1"># data for each player of the different fantasy point estimates. 
</span>    <span class="c1"># This array is used to generate the KDE.
</span>    <span class="n">training_data</span> <span class="o">=</span> <span class="p">[]</span>
    <span class="n">training_data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'fp_pts'</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
    <span class="n">training_data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'nfl_pts'</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
    <span class="n">training_data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'espn_pts'</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
    <span class="n">training_data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'fs_pts'</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
    <span class="n">training_data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'si_pts'</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
    <span class="c1"># clean the training_data for NaN values
</span>    <span class="n">training_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">training_data</span> <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">!=</span> <span class="s">'nan'</span><span class="p">]</span> 
    <span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
        <span class="n">training_data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>

    <span class="c1"># this sets up and runs the non-parametric estimation
</span>    <span class="n">kde</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">nonparametric</span><span class="p">.</span><span class="n">KDEUnivariate</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
    <span class="c1"># Estimate the densities
</span>    <span class="n">kde</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'gau'</span><span class="p">,</span> <span class="n">bw</span><span class="o">=</span><span class="s">'silverman'</span><span class="p">,</span> <span class="n">fft</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span>

    <span class="c1"># This for loop processes to find the median projection
</span>    <span class="n">ci_50</span> <span class="o">=</span> <span class="mi">0</span> <span class="c1"># initialize median value to zero
</span>    <span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="nb">len</span><span class="p">(</span><span class="n">kde</span><span class="p">.</span><span class="n">cdf</span><span class="p">)):</span>
        <span class="k">if</span> <span class="n">kde</span><span class="p">.</span><span class="n">cdf</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&lt;</span> <span class="mf">0.50</span><span class="p">:</span>
            <span class="n">i</span><span class="o">+=</span><span class="mi">1</span>
        <span class="k">if</span> <span class="n">kde</span><span class="p">.</span><span class="n">cdf</span><span class="p">[</span><span class="n">i</span><span class="p">]</span> <span class="o">&gt;=</span> <span class="mf">0.50</span><span class="p">:</span>
            <span class="n">ci_50</span> <span class="o">=</span> <span class="n">kde</span><span class="p">.</span><span class="n">support</span><span class="p">[</span><span class="n">i</span><span class="p">]</span>
            <span class="k">break</span>

    <span class="c1"># Add data to main dataframe
</span>    <span class="n">df</span><span class="p">[</span><span class="s">'pts'</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">=</span><span class="n">ci_50</span> <span class="c1"># add median projection
</span>    <span class="n">df</span><span class="p">[</span><span class="s">'kde_icdf'</span><span class="p">][</span><span class="n">j</span><span class="p">]</span><span class="o">=</span><span class="n">kde</span><span class="p">.</span><span class="n">icdf</span> <span class="c1"># add icdf for whisker plot construction
</span>
<span class="c1"># export the dataset to a .csv file
</span><span class="n">df</span><span class="p">.</span><span class="n">to_csv</span><span class="p">(</span><span class="sa">r</span><span class="s">'./prepared_data/2020_ffl_df.csv'</span><span class="p">)</span>
</code></pre></div></div>

<p>The above code takes a while to run, and since I’m an aforementioned python n00b (and because I’d only need to run this once to generate my final dataset), I couldn’t be bothered to speed it up.  If you’re a python/data science wizard who has any tips on this, bang my inbox.  Something something Cunningham’s law.  But anyway, once this code finished running, I had a model for doing KDE estimation!</p>

<h2 id="an-applied-example-of-kde">An applied example of KDE</h2>

<p>As the final part of this post, I want include a specific example of how the KDE estimation works for a given draft number to provide context for how DAsHA would ultimately work.  In the following code snippet, <code class="language-plaintext highlighter-rouge">j</code> represents an arbitrary draft order from which we can generate a Gaussian KDE probability density function for the player corresponding to that draft rank (i.e. it would be represent which pick you’d be making as the fantasy football manager).</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">j</span> <span class="o">=</span> <span class="mi">125</span>

<span class="n">training_data</span> <span class="o">=</span> <span class="p">[]</span>
<span class="n">training_data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'fp_pts'</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
<span class="n">training_data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'nfl_pts'</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
<span class="n">training_data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'espn_pts'</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
<span class="n">training_data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'fs_pts'</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
<span class="n">training_data</span><span class="p">.</span><span class="n">append</span><span class="p">(</span><span class="n">df</span><span class="p">[</span><span class="s">'si_pts'</span><span class="p">][</span><span class="n">j</span><span class="p">])</span>
<span class="n">training_data</span> <span class="o">=</span> <span class="p">[</span><span class="n">x</span> <span class="k">for</span> <span class="n">x</span> <span class="ow">in</span> <span class="n">training_data</span> <span class="k">if</span> <span class="nb">str</span><span class="p">(</span><span class="n">x</span><span class="p">)</span> <span class="o">!=</span> <span class="s">'nan'</span><span class="p">]</span>
<span class="k">if</span> <span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span> <span class="o">==</span> <span class="mi">0</span><span class="p">:</span>
    <span class="n">training_data</span> <span class="o">=</span> <span class="p">[</span><span class="mi">0</span><span class="p">]</span>

<span class="c1"># this sets up and runs the non-parametric estimation
</span><span class="n">kde</span> <span class="o">=</span> <span class="n">sm</span><span class="p">.</span><span class="n">nonparametric</span><span class="p">.</span><span class="n">KDEUnivariate</span><span class="p">(</span><span class="n">training_data</span><span class="p">)</span>
<span class="n">kde</span><span class="p">.</span><span class="n">fit</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="s">'gau'</span><span class="p">,</span> <span class="n">bw</span><span class="o">=</span><span class="s">'silverman'</span><span class="p">,</span> <span class="n">fft</span><span class="o">=</span><span class="bp">False</span><span class="p">)</span> <span class="c1"># Estimate the densities
</span></code></pre></div></div>

<p>The various point estimates for that player will be indicated by red ‘+’s at the bottom of the graph. The KDE lets us center a normal gaussian distribution (with area = <code class="language-plaintext highlighter-rouge">1/n</code>) for <code class="language-plaintext highlighter-rouge">n</code> point estimates) over each of these point estimates. Then, to generate the probability density function, we sum all of these “kernels” together - this summation is the orange line in the graph below.</p>

<p>Finally, the following code snippet generates a histogram from the KDE PDF showing the 1- and 2- standard deviation confidence intervals.</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">fig</span> <span class="o">=</span> <span class="n">plt</span><span class="p">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">ax</span> <span class="o">=</span> <span class="n">fig</span><span class="p">.</span><span class="n">add_subplot</span><span class="p">(</span><span class="mi">111</span><span class="p">)</span>

<span class="c1"># Plot the histrogram
</span><span class="n">ax</span><span class="p">.</span><span class="n">hist</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">bins</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="bp">True</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s">'Histogram from forecasts'</span><span class="p">,</span>
        <span class="n">zorder</span><span class="o">=</span><span class="mi">5</span><span class="p">,</span> <span class="n">edgecolor</span><span class="o">=</span><span class="s">'k'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="c1"># Plot the KDE as fitted using the default arguments
</span><span class="n">ax</span><span class="p">.</span><span class="n">plot</span><span class="p">(</span><span class="n">kde</span><span class="p">.</span><span class="n">support</span><span class="p">,</span> <span class="n">kde</span><span class="p">.</span><span class="n">density</span><span class="p">,</span> <span class="n">lw</span><span class="o">=</span><span class="mi">3</span><span class="p">,</span> 
    <span class="n">label</span><span class="o">=</span><span class="s">'KDE from projections'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">10</span><span class="p">)</span>

<span class="c1"># Plot the samples
</span><span class="n">ax</span><span class="p">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">training_data</span><span class="p">,</span> <span class="n">np</span><span class="p">.</span><span class="nb">abs</span><span class="p">(</span><span class="n">np</span><span class="p">.</span><span class="n">random</span><span class="p">.</span><span class="n">randn</span><span class="p">(</span><span class="nb">len</span><span class="p">(</span><span class="n">training_data</span><span class="p">)))</span><span class="o">/</span><span class="mi">100000</span><span class="p">,</span>
    <span class="n">marker</span><span class="o">=</span><span class="s">'+'</span><span class="p">,</span> <span class="n">color</span><span class="o">=</span><span class="s">'red'</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=</span><span class="mi">20</span><span class="p">,</span> 
    <span class="n">label</span><span class="o">=</span><span class="s">'Point Forecasts'</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.5</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">legend</span><span class="p">(</span><span class="n">loc</span><span class="o">=</span><span class="s">'best'</span><span class="p">)</span>
<span class="n">ax</span><span class="p">.</span><span class="n">grid</span><span class="p">(</span><span class="bp">True</span><span class="p">,</span> <span class="n">zorder</span><span class="o">=-</span><span class="mi">5</span><span class="p">)</span>
</code></pre></div></div>

<p><img src="../../../media/KDE_demo.PNG" alt="KDE Demo" width="740px" /></p>

<p>This distribution is then used to generate median point estimations and confidence intervals for each player. For example, this code</p>

<div class="language-python highlighter-rouge"><div class="highlight"><pre class="highlight"><code><span class="n">box_plot_data</span><span class="o">=</span><span class="n">kde</span><span class="p">.</span><span class="n">icdf</span>
<span class="n">plt</span><span class="p">.</span><span class="n">boxplot</span><span class="p">(</span><span class="n">box_plot_data</span><span class="p">,</span> <span class="n">vert</span><span class="o">=</span><span class="bp">False</span><span class="p">,</span> <span class="n">labels</span><span class="o">=</span><span class="p">[</span><span class="n">df</span><span class="p">[</span><span class="s">'Name'</span><span class="p">][</span><span class="n">j</span><span class="p">]])</span>
<span class="n">plt</span><span class="p">.</span><span class="n">show</span><span class="p">()</span>
</code></pre></div></div>

<p>generates the following confidence interval for a given player (in this case, Kareem Hunt)</p>

<p><img src="../../../media/confidence_interval_demo.png" alt="CI Demo" width="740px" /></p>

<h2 id="conclusion-and-further-reading">Conclusion and Further Reading</h2>

<p>And that’s all for now!  I threw a lot of data science concepts out in this post and I don’t want to share too much too quickly.  Hopefully, after reading this far you now understand:</p>

<ol>
  <li>The value of using Gaussian KDEs for projecting fantasy football player performance</li>
  <li>How to collect data to run build this type of model</li>
  <li>How to use popular python libraries to generate a Gaussian KDE from the given data.</li>
</ol>

<p>In <a href="/2020/11/19/building-a-fantasy-football-draft-assistance-algorithm-part-2.html">Part Two</a>, we’ll cover how implement this model as a real-time draft assistant tool, and how I used it to out-draft my friends.  I look forward to sharing!</p>

<p>Finally, I just wanted to thank my brother, <a href="https://github.com/owingit">Owen Martin</a>, for code-reviewing my shitty Python.  He writes Python all the time and is much better at this than me.  Thanks, Bro!</p>
